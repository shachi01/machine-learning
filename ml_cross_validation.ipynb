{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation Purpose and Applications \n",
    "### Author: Shachi Kaul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,cross_val_predict,StratifiedKFold,GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestones\n",
    "- Load sklearn's breast_cancer dataset\n",
    "- Ways of Data Partitioning, Training & Evaluation\n",
    "    - train_test_split \n",
    "    - Cross-Validation\n",
    "- Applications of Cross-Validation   \n",
    "    - Choose your model\n",
    "    - Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= loaded_data.data, columns=[loaded_data.feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Framing target column in our dataframe\n",
    "df['target'] = pd.Series(data=loaded_data.target, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
       "0       17.99        10.38         122.80    1001.0         0.11840   \n",
       "1       20.57        17.77         132.90    1326.0         0.08474   \n",
       "2       19.69        21.25         130.00    1203.0         0.10960   \n",
       "3       11.42        20.38          77.58     386.1         0.14250   \n",
       "4       20.29        14.34         135.10    1297.0         0.10030   \n",
       "\n",
       "  mean compactness mean concavity mean concave points mean symmetry  \\\n",
       "0          0.27760         0.3001             0.14710        0.2419   \n",
       "1          0.07864         0.0869             0.07017        0.1812   \n",
       "2          0.15990         0.1974             0.12790        0.2069   \n",
       "3          0.28390         0.2414             0.10520        0.2597   \n",
       "4          0.13280         0.1980             0.10430        0.1809   \n",
       "\n",
       "  mean fractal dimension  ...   worst texture worst perimeter worst area  \\\n",
       "0                0.07871  ...           17.33          184.60     2019.0   \n",
       "1                0.05667  ...           23.41          158.80     1956.0   \n",
       "2                0.05999  ...           25.53          152.50     1709.0   \n",
       "3                0.09744  ...           26.50           98.87      567.7   \n",
       "4                0.05883  ...           16.67          152.20     1575.0   \n",
       "\n",
       "  worst smoothness worst compactness worst concavity worst concave points  \\\n",
       "0           0.1622            0.6656          0.7119               0.2654   \n",
       "1           0.1238            0.1866          0.2416               0.1860   \n",
       "2           0.1444            0.4245          0.4504               0.2430   \n",
       "3           0.2098            0.8663          0.6869               0.2575   \n",
       "4           0.1374            0.2050          0.4000               0.1625   \n",
       "\n",
       "  worst symmetry worst fractal dimension target  \n",
       "0         0.4601                 0.11890      0  \n",
       "1         0.2750                 0.08902      0  \n",
       "2         0.3613                 0.08758      0  \n",
       "3         0.6638                 0.17300      0  \n",
       "4         0.2364                 0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways of Data Partitioning, Training & Evaluation\n",
    "For building the model, data is partitioned into train/test. There are various ways of doing it, each having its own limitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Not using random_state by default generates random integer every time when code is run. Thsi results into different results.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df.drop(['target'],axis=1), df['target'],test_size=0.2,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(xtrain,ytrain)\n",
    "lg_model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target'],axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold & Stratified K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.9736842105263158, 0.9649122807017544, 0.9736842105263158, 0.9385964912280702, 0.9736842105263158]\n",
      "K-Fold Score: 0.9649122807017545\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "scores = []\n",
    "#cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=False)\n",
    "cv = KFold(n_splits=5, random_state=seed, shuffle=False) \n",
    "for train_index, test_index in cv.split(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)    \n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-learn library:\n",
    "    - cross_val_score: To compute score of each test fold. \n",
    "    - cross_val_predict: To predict and returns predicted score of each test fold.\n",
    "Default, integer cv parameter assumes StratifiedK-Fold. As shown below, it is Stratified 5-folds implemented via cross_val_Score but you can also set cv to K-Fold commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.93043478 0.93913043 0.97345133 0.94690265 0.96460177]\n",
      "Predicted class for each record: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "K-Fold Score: 0.9509041939207385\n",
      "Total records: 569, Total predicted values: 569\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "cv_scores_5_folds = cross_val_score(model,X,y,cv=5)\n",
    "#cv_scores_5_folds = cross_val_score(model,X,y,cv=KFold(n_splits=5))\n",
    "\n",
    "cv_predicts_5_folds = cross_val_predict(model,X,y,cv=5)\n",
    "\n",
    "print(\"Accuracy score in each iteration: {}\".format(cv_scores_5_folds))\n",
    "print(\"Predicted class for each record: {}\".format(cv_predicts_5_folds))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(cv_scores_5_folds)))\n",
    "print(\"Total records: {}, Total predicted values: {}\".format(df.shape[0],len(cv_predicts_5_folds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your model\n",
    "    Aim: To compare classifier using cross_val_score. \n",
    "    Conclusion: Not much difference in scores but RandomForest performed best among three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Score of RandomForest: 0.9561831473643709\n",
      "K-Fold Score of Decision Tree: 0.9174297806848788\n",
      "K-Fold Score of Logistic Regression: 0.9509041939207385\n"
     ]
    }
   ],
   "source": [
    "rf_cv_scores_5_folds = cross_val_score(RandomForestClassifier(random_state=seed),X,y,cv=5)\n",
    "print(\"K-Fold Score of RandomForest: {}\".format(np.mean(rf_cv_scores_5_folds)))\n",
    "\n",
    "dt_cv_scores_5_folds = cross_val_score(DecisionTreeClassifier(random_state=seed),X,y,cv=5)\n",
    "print(\"K-Fold Score of Decision Tree: {}\".format(np.mean(dt_cv_scores_5_folds)))\n",
    "\n",
    "log_cv_scores_5_folds = cross_val_score(LogisticRegression(random_state=seed),X,y,cv=5)\n",
    "print(\"K-Fold Score of Logistic Regression: {}\".format(np.mean(log_cv_scores_5_folds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning of RandomForest \n",
    "\n",
    "- Model which was simply trained on manually estimated parameters may perform better if its parameters get more tuned as per data. This tuning is necessary to improvise your model which is about testing cartesian product of parameters using Grid Search or Random Search. \n",
    "\n",
    "- <b>GridSearchCV: </b>\n",
    "Scikit-learn library to define ranges of parameters, perform CrossValidation with each combination of cartesian product of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = list(range(5,20))\n",
    "maxdepth = list(range(2,10)) \n",
    "\n",
    "hyperparas = dict(n_estimators=n_estimators,max_depth=maxdepth)\n",
    "grid_rf_model = GridSearchCV(estimator=rf_model, param_grid=hyperparas, cv=5)\n",
    "improved_model = grid_rf_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9648506151142355\n",
      "Best parameters for best score: {'max_depth': 6, 'n_estimators': 19}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score:\",improved_model.best_score_)\n",
    "print(\"Best parameters for best score:\",improved_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing best parameters returned by GridSearchCV\n",
    "    Conclusion: Score is improved in an accuracy of approx 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 0.9649403616775682\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(max_depth=6, n_estimators= 19, random_state=seed)\n",
    "score = cross_val_score(rf_model,X,y,cv=5)\n",
    "print(\"CV Score:\",np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
